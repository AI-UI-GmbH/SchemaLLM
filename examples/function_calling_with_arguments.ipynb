{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pf/miniconda3/envs/cu118/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "CUDA extension not installed.\n",
      "CUDA extension not installed.\n"
     ]
    }
   ],
   "source": [
    "from schemallm import SchemaLLM\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"TheBloke/Llama-2-7B-Chat-GPTQ\", device_map=\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"TheBloke/Llama-2-7B-Chat-GPTQ\")\n",
    "schema_llm = SchemaLLM(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create functions for choosing function and building arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from typing import List, Literal, Callable\n",
    "from pydantic import BaseModel, create_model\n",
    "\n",
    "\n",
    "class Function(BaseModel):\n",
    "    func: Callable\n",
    "    func_description: str\n",
    "    arg_description: str\n",
    "\n",
    "\n",
    "def choose_function(situation: str, functions: List[Function]) -> Function:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        situation: str, prompt explaining situation\n",
    "        functions: List[Function]\n",
    "    \"\"\"\n",
    "    function_names = [f.func.__name__ for f in functions]\n",
    "    # build input text\n",
    "    prompt = situation + \"\\n\\nChoose one of following functions:\\n\"\n",
    "    prompt += \"\\n\".join([f\"{name}\\n  description: {f.func_description}\" for name, f in zip(function_names, functions)])\n",
    "    # build output schema\n",
    "    func_choose_output_schema = create_model(\"TmpModel\", chosen_function=(Literal[tuple(function_names)], ...)).schema()\n",
    "    # choose function\n",
    "    func_choose_output = schema_llm.generate(prompt=prompt, schema=func_choose_output_schema)\n",
    "    chosen_function_name = func_choose_output[\"chosen_function\"]\n",
    "    chosen_function = functions[function_names.index(chosen_function_name)]\n",
    "    return chosen_function\n",
    "\n",
    "\n",
    "def build_function_argument(situation: str, function: Function) -> dict:\n",
    "    # build arguments schema\n",
    "    argspec = inspect.getfullargspec(function.func)\n",
    "    arg_names = argspec.args\n",
    "    arg_annotations = argspec.annotations\n",
    "    schema_annotation = {}\n",
    "    for arg_name in arg_names:\n",
    "        if arg_name not in arg_annotations:\n",
    "            raise Exception(f\"Argument {arg_name} of function {function.func.__name__} is not annotated.\")\n",
    "        arg_annotation = arg_annotations[arg_name]\n",
    "        schema_annotation[arg_name] = (arg_annotation, ...)\n",
    "    kwargs_schema = create_model(\"TmpModel\", **schema_annotation).schema()\n",
    "    # build arguments for function\n",
    "    prompt = (\n",
    "        situation\n",
    "        + f\"\\n\\npython function {function.func.__name__} is chosen. Continue to build arguments for the function, arguments description:\\n\"\n",
    "        + function.arg_description\n",
    "    )\n",
    "    kwargs = schema_llm.generate(prompt=prompt, schema=kwargs_schema)\n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define situation and available tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "situation = \"\"\"I need today's stock price of APPLE\"\"\"\n",
    "\n",
    "\n",
    "def google_search(text: str):\n",
    "    print(f\"search {text} in google\")\n",
    "\n",
    "\n",
    "def hackernews_search(text: str):\n",
    "    print(f\"search {text} in hackernews\")\n",
    "\n",
    "\n",
    "functions = [\n",
    "    Function(\n",
    "        func=google_search,\n",
    "        func_description=\"search via google search engine\",\n",
    "        arg_description=\"- text: string, text used for search in google\",\n",
    "    ),\n",
    "    Function(\n",
    "        func=hackernews_search,\n",
    "        func_description=\"search in hackernews forum\",\n",
    "        arg_description=\"- text: string, text used for search in hackernews\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the task and call function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pf/miniconda3/envs/cu118/lib/python3.10/site-packages/transformers/generation/utils.py:1518: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search Apple Inc. stock price in google\n"
     ]
    }
   ],
   "source": [
    "func = choose_function(\n",
    "    situation=situation,\n",
    "    functions=functions\n",
    ")\n",
    "kwargs = build_function_argument(\n",
    "    situation=situation,\n",
    "    function=func\n",
    ")\n",
    "func.func(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cu118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
